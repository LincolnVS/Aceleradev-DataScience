{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula 10 - Validação.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsR4pw02xLex",
        "colab_type": "text"
      },
      "source": [
        "![Codenation](https://forum.codenation.com.br/uploads/default/original/2X/2/2d2d2a9469f0171e7df2c4ee97f70c555e431e76.png)\n",
        "\n",
        "__Autor__: Kazuki Yokoyama (kazuki.yokoyama@ufrgs.br)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi4xZxcfBA2U",
        "colab_type": "text"
      },
      "source": [
        "# Validação de modelos\n",
        "\n",
        "![cover](https://scikit-learn.org/stable/_images/grid_search_workflow.png)\n",
        "\n",
        "Neste módulo, falaremos sobre validação de modelos de predição. As ideias apresentadas aqui aplicam-se _mutati mutandis_ tanto para regressão, quanto para classificação. Veremos porque utilizar os mesmos dados de treinamento para avaliar o desempenho do modelo é um erro e como podemos fazer certo com dados de validação e _cross-validation_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAxxSlo3QrZV",
        "colab_type": "text"
      },
      "source": [
        "## Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMxYy1NkQwW6",
        "colab_type": "code",
        "outputId": "57fb1be9-e615-49d5-cf9d-3c33250e917e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import functools\n",
        "from math import sqrt\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "import scipy.stats as sct\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.datasets import load_digits, make_blobs, make_classification\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV, LeaveOneOut, cross_val_score, train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNbPRHkKQyv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Algumas configurações para o matplotlib.\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.core.pylabtools import figsize\n",
        "\n",
        "\n",
        "figsize(12, 12)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8onCO86Q2Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV6lPoW_aX4k",
        "colab_type": "text"
      },
      "source": [
        "## Validação em treinamento e teste\n",
        "\n",
        "Sabemos que além de treinar um modelo, precisamos também avaliar o seu desempenho em novos dados, não vistos durante o treinamento. Geralmente, medimos o desempenho de um modelo através de uma função do erro: quanto menor, melhor. E utilizamos essa função para escolher o melhor modelo, ou a melhor combinação de hiperparâmetros de um modelo.\n",
        "\n",
        "Acontece que o desempenho de um modelo quando avaliado sobre os dados de treinamento é bem diferente quando avaliado sobre dados nunca antes vistos. Considere os gráficos abaixo (retirados de Tibshirani et al.):\n",
        "\n",
        "![terminology](https://drive.google.com/uc?export=download&id=1Pjiyc1WbXH9Q9GJFkZdOOw2u8_abR6Kq)\n",
        "\n",
        "O gráfico à esquerda mostra dados gerados a partir da curva em preto e três modelos de regressão treinados para esses dados. Repare como há um crescente nível de ajuste fino dos modelos aos dados de treinamento, do mais rígido (laranja) ao mais ajustado (verde). Chamamos esse nível de adequação do modelo aos dados de flexibilidade: quanto mais flexível, mais liberdade o modelo tem para se ajustar aos dados. \n",
        "\n",
        "Podemos alterar a flexibilidade mudando de modelo (certos modelos são naturalmente mais flexíveis que outros), ou alterando os hiperparâmetros de um mesmo tipo de modelo como, por exemplo, ao criarmos mais variáveis explicativas (e.g., polinomiais) para um modelo de regressão linear.\n",
        "\n",
        "O gráfico mostra os dois tipos. Em laranja, temos um modelo de regressão linear. Em azul, um modelo de _spline_ (uma forma de interpolação numérica capaz de se ajustar a dados altamente não lineares). E em verde, um _spline_ ainda mais flexível, através de alterações nos parâmetros do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKYMh9pChw4Y",
        "colab_type": "text"
      },
      "source": [
        "O mais interessante porém encontra-se no gráfico à direita. Nele, são mostradas as curvas de erro (medido pelo MSE) dos modelos em relação aos dados de treinamento (em cinza), aos dados de teste (em vermelho) e o mínimo erro teórico (linha tracejada), em função da flexibilidade do modelo. Os pontos representam o desempenho de cada um dos modelos nesses conjuntos.\n",
        "\n",
        "Note como o erro de treinamento é dado por uma curva decrescente: quanto mais flexível é o modelo, menor é o seu erro no conjunto de treinamento. Baseado somente nessa curva, poderíamos supor erradamente que modelos mais flexíveis são sempre melhores. No caso extremo, poderíamos criar um modelo tão flexível quanto conseguíssemos (por exemplo, adicionando centenas ou milhares de variáveis novas) até que alcançássemos um erro próximo de zero. Infelizmente, esse não é o caso (ou felizmente, senão seria muito sem graça).\n",
        "\n",
        "Se fizermos isso, estaremos criando modelos que fazem __overfitting__ dos dados: o modelo \"decora\" os dados de treinamento e tenta se ajustar o melhor possível a eles, perdendo capacidade de generalização. Ao perder generalização, o modelo torna-se incapaz de realizar predições adequadas para dados nunca antes vistos.\n",
        "\n",
        "![overfitting](https://drive.google.com/uc?export=download&id=1FFk46KAdZpq6kwcKiysXspsO0fhQPd_u)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZkxLL3Aloa8",
        "colab_type": "text"
      },
      "source": [
        "Como o erro de treinamento não é uma medida muito confiável do desempenho dos modelos, precisamos de outra forma de avaliá-los. Essa outra forma é através do erro de teste. O erro de teste é um medida de desempenho do modelo em dados não utilizados durante o treinamento, ou seja, totalmente novos para o modelo.\n",
        "\n",
        "Poderíamos pensar que o erro de teste segue o mesmo padrão do erro de treinamento, ou seja, que ele aumenta com a flexibilidade do modelo. Mas esse não é o caso.\n",
        "\n",
        "Na verdade, o erro de teste tem a forma clássica de 'U': ele começa alto para modelos pouco flexíveis, diminui com o aumento da flexibilidade até certo ponto (lembre deste \"certo ponto\"), e depois volta a crescer indefinidamente com modelos demasiadamente flexíveis.\n",
        "\n",
        "Antes de entedermos o compartamento do gráfico à direita, vale lembrar que o erro total cometido pelo modelo (aqui o MSE) é a soma do erro derivado da variância, do viés e do erro irredutível. E que quanto mais flexível é um modelo, menor é seu viés, mas maior é sua variância. Daí o _tradeoff_ viés-variância.\n",
        "\n",
        "Agora, observe a curva vermelha no gráfico à direita. O modelo laranja (regressão linear) possui baixa flexibilidade, mas alto viés. Isso o leva a cometer outro tipo de erro: __underfitting__. Com _underfitting_, o modelo é demasiadamente simples para explicar a realidade dos dados, também levando à predições fracas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYBn-Cznn8ar",
        "colab_type": "text"
      },
      "source": [
        "O modelo em azul (um _spline_) possui um viés menor, mas uma variância naturalmente maior que uma regressão linear simples. Porém, a diminuição no viés superou o crescimento da variância, de forma que a soma dos dois resultou em um erro total menor.\n",
        "\n",
        "Se continuarmos aumentando a flexibilidade do _spline_, como fazemos com o modelo em verde, chegaremos no caso onde a diminuição do viés não compensou o crescimento rápido da variância do modelo, resultando em um novo crescimento do erro total.\n",
        "\n",
        "Analisando somente o erro de treinamento, seríamos levados a crer que o modelo verde é o melhor. Porém, de conhecimento do erro de teste, vemos que ele na verdade apresenta um erro real quase tão alto quanto a regressão linear simples. E que o melhor modelo é de fato o _spline_ intermediário em azul."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3BY8ABEqS5y",
        "colab_type": "text"
      },
      "source": [
        "Agora que sabemos que o verdadeiro desempenho de um modelo é dado pelo seu erro em dados nunca antes vistos, como obtemos esse valor na prática?\n",
        "\n",
        "Essa não é uma tarefa tão trivial. Veremos agora algumas abordagens para esse problema, começando pelo conjunto de teste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFRrs7Z-qvqd",
        "colab_type": "text"
      },
      "source": [
        "## Conjuntos de validação e teste\n",
        "\n",
        "As curvas no gráfico à direita foram obtidas avaliando-se o desempenho em dados nunca antes vistos. Isso só foi possível porque era um experimento onde se conhecia o verdadeiro processo de geração de dados (a curva preta no gráfico à esquerda), sendo então possível se criar mais dados exclusivamente para o teste. Na vida real, não dispomos de tal luxo.\n",
        "\n",
        "O que possuímos é um conjunto de dados limitado, da onde devemos treinar o modelo, avaliar seu desempenho, tunar hiperparâmetros etc. Como fazemos tanto com tão pouco?\n",
        "\n",
        "Uma primeira abordagem é separar o conjunto de dados em dois grupos, reservando uma parte para treinamento do modelo e outra para o seu teste. Essa abordagem é chamada de \"conjunto de validação e teste (ou _hold-out_)\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOrT34OMxWHZ",
        "colab_type": "text"
      },
      "source": [
        "![validation-test](https://drive.google.com/uc?export=download&id=17hsdHMYXcJEeugN4DT5Wriz63McvaqrF)\n",
        "\n",
        "Nessa abordagem, dividimos o conjunto original de dados em três partes: treinamento, validação e teste (_hold-out_). É altamente indicado randomizar o conjunto de dados antes de fazer o particionamento. Isso pode evitar a introdução de um viés devido a ordenação do conjunto de dados original.\n",
        "\n",
        "O conjunto de treinamento é autoexplicativo. Ele será utilizado para treinar o nosso modelo. Essa é onde fica a maior parte dos dados, com cerca de 50% ~ 70% dos dados. Já foi mostrado como o erro do modelo medido nesses dados pode ser enganoso.\n",
        "\n",
        "Para ajustarmos os hiperparâmetros do modelo, utilizamos o conjunto de validação. Cada combinação de hiperparâmetros é treinada sobre os dados de treinamento e avaliada sobre os dados de validação. Como esses dados não participaram do treinamento do modelo, o erro é uma boa medida do real desempenho do modelo sobre dados nunca vistos.\n",
        "\n",
        "Por fim, quando tivermos escolhido o modelo e a melhor combinação de hiperparâmetros, utilizamos o conjunto de teste para a avaliação final do desempenho do modelo. Esse é o desempenho que será reportado. Assim como o de validação, o erro de teste é naturalmente maior do que o erro de treinamento, mas também mais real."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjpwC6c6zzfO",
        "colab_type": "text"
      },
      "source": [
        "Apesar de ser simples o suficiente para ser implementada sem dificuldades, essa abordagem possui alguns problemas. O primeiro é a redução da quantidade de dados disponíveis para realizar o treinamento do modelo. Alguns modelos não alcançam bom resultado se não forem treinados com bastante dados. Diminuir a quantidade de dados de treinamento nesse caso é de nenhuma ajuda. Como resultado, temos que o erro reportado pela validação superestima o verdadeiro erro de teste, que seria obtido se o modelo fosse treinado com todos dados disponíveis.\n",
        "\n",
        "O segundo problema é que o resultado do modelo pode ser susceptível à escolha dos dados de treinamento/validação/teste. Isso significa que diferentes particionamentos do conjunto de dados original pode levar a modelos com desempenhos bem diferentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocimT9R91PD5",
        "colab_type": "text"
      },
      "source": [
        "Apesar desses problemas, essa abordagem inicial nos deixa uma lição que levaremos daqui em diante: sempre separe uma parte do conjunto de dados original para a realização da performance final do modelo, o conjunto de teste (ou _hold-out_)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlP5645hyaDU",
        "colab_type": "code",
        "outputId": "1e995574-2ea8-40c9-e6cd-6b0785a0a380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "digits_dataset = load_digits()\n",
        "\n",
        "images = digits_dataset.images\n",
        "target = digits_dataset.target\n",
        "\n",
        "images.shape, target.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1797, 8, 8), (1797,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPsN1DWHzLzm",
        "colab_type": "code",
        "outputId": "b4f1c867-71db-4315-8e08-3f0e9835a5e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "source": [
        "images_and_labels = list(zip(images, target))\n",
        "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
        "    plt.subplot(2, 4, index + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    plt.title('Training: %i' % label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAADACAYAAAAA7HuUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x864 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d917ZMi70DF9",
        "colab_type": "code",
        "outputId": "5bb2c1ae-33e1-4456-883b-0df865a47c1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "digits = images.reshape((len(images), -1))\n",
        "\n",
        "digits.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1797, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRiYlhNF06Mt",
        "colab_type": "code",
        "outputId": "0ea7b425-db86-4c07-9aff-d6888e65a10b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_val, X_test, y_train_val, y_test = train_test_split(digits, target, test_size=0.25)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=1/3)\n",
        "\n",
        "X_train.shape, X_val.shape, X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((898, 64), (449, 64), (450, 64))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epcTP6PZCZMT",
        "colab_type": "code",
        "outputId": "f98a4d44-9da3-4ec9-d502-6e7df2fb077a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "criterions = [\"gini\", \"entropy\"]\n",
        "max_depths = [2**i for i in range(5)]\n",
        "min_samples_leaves = [2**i for i in range(5)]\n",
        "\n",
        "param_candidates = [(criterion, max_depth, min_samples_leaf)\n",
        "                    for criterion in criterions\n",
        "                    for max_depth in max_depths\n",
        "                    for min_samples_leaf in min_samples_leaves]\n",
        "\n",
        "random_candidates_idx = sorted(np.random.choice(range(len(param_candidates)), size=5, replace=False))\n",
        "\n",
        "random_candidates = []\n",
        "for random_idx in random_candidates_idx:\n",
        "    random_candidates.append(param_candidates[random_idx])\n",
        "    \n",
        "    print(f\"{random_idx}: {param_candidates[random_idx]}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8: ('gini', 2, 8)\n",
            "22: ('gini', 16, 4)\n",
            "25: ('entropy', 1, 1)\n",
            "28: ('entropy', 1, 8)\n",
            "46: ('entropy', 16, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw_PCmgmDnLY",
        "colab_type": "code",
        "outputId": "469b06e0-3b04-490d-e341-ce73ac850c75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "results = {}\n",
        "for param_candidate in param_candidates:\n",
        "    criterion = param_candidate[0]\n",
        "    max_depth = param_candidate[1]\n",
        "    min_samples_leaf = param_candidate[2]\n",
        "    \n",
        "    tree = DecisionTreeClassifier(criterion=criterion,\n",
        "                                  max_depth=max_depth,\n",
        "                                  min_samples_leaf=min_samples_leaf)\n",
        "    \n",
        "    tree.fit(X_train, y_train)\n",
        "    \n",
        "    y_val_pred = tree.predict(X_val)\n",
        "    \n",
        "    results[param_candidate] = accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "\n",
        "for random_candidate in random_candidates:\n",
        "    print(f\"{random_candidate} score: {results[random_candidate]}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('gini', 2, 8) score: 0.3051224944320713\n",
            "('gini', 16, 4) score: 0.8240534521158129\n",
            "('entropy', 1, 1) score: 0.16926503340757237\n",
            "('entropy', 1, 8) score: 0.16926503340757237\n",
            "('entropy', 16, 2) score: 0.8663697104677061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laQXsbQhLCAt",
        "colab_type": "code",
        "outputId": "53de62fe-0f8c-4ae4-e5c1-c66b2bf35187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "best_params = max(results.keys(), key=lambda k: results[k])\n",
        "\n",
        "best_params, results[best_params]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('entropy', 16, 2), 0.8663697104677061)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEivQn_aMNEY",
        "colab_type": "code",
        "outputId": "acb1d432-296f-446a-a978-e06fa5cb83f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "best_tree = DecisionTreeClassifier(criterion=best_params[0],\n",
        "                                   max_depth=best_params[1],\n",
        "                                   min_samples_leaf=best_params[2])\n",
        "\n",
        "y_test_pred = tree.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "accuracy_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7711111111111111"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5pwkCUmRhoa",
        "colab_type": "code",
        "outputId": "52ef9e81-e868-4596-ce3a-f40c31f6a3c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_val = np.concatenate((X_train, X_val))\n",
        "y_train_val = np.concatenate((y_train, y_val))\n",
        "\n",
        "y_test_pred = DecisionTreeClassifier(criterion=best_params[0],\n",
        "                                   max_depth=best_params[1],\n",
        "                                   min_samples_leaf=best_params[2]).fit(X_train_val, y_train_val).predict(X_test)\n",
        "\n",
        "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "accuracy_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8644444444444445"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCIQ944c1eSZ",
        "colab_type": "text"
      },
      "source": [
        "## _Cross-validation_\n",
        "\n",
        "Vimos que uma deficiência da abordagem do conjunto de validação é diminuir a quantidade de dados do conjunto de treinamento. O método do _cross-validation_ nos permite realizar validação sem abrir mão dos dados de treinamento. _Cross-validation_ (ou validação cruzada) é uma técnica estatística iterativa para estimação do erro de teste, ou seja, sobre dados nunca antes vistos, sem que seja necessário separar um conjunto exclusivo para esse fim.\n",
        "\n",
        "> De agora em diante, consideramos que uma parte do conjunto original de dados já foi separada para o conjunto de teste (ou _hold-out_). O que resta, iremos chamar de \"conjunto de _cross-validation_\".\n",
        "\n",
        "Para realizar o o $k$-_fold cross-validation_, embaralhamos e dividimos o conjunto de _cross-validation_ em $k$ partes o mais iguais possível chamadas _folds_. Na primeira iteração do método, separamos a primeira _fold_ como conjunto de validação e utilizamos as $k-1$ _folds_ restantes para o treinamento do modelo. O modelo treinado é então avaliado na primeira _fold_ e tem seu desempenho registrado, $\\text{MSE}_{1}$. Na segunda iteração, separamos a segunda _fold_ para teste e utilizamos as $k-1$ _folds_ para treinamento. O desempenho de teste do modelo na segunda _fold_ é registrado em $\\text{MSE}_{2}$. Repetimos esse processo por todas $k$ _folds_, obtendo $k$ erros $\\text{MSE}_{i} (i \\in \\{1, 2, \\cdots, k\\})$. No final, calculamos a média dos $k$ $\\text{MSE}$ obtidos como o erro de validação do modelo. Esse erro de validação é utilizado para comparar modelos com diferentes combinações de hiperparâmetros. Em outras palavras, o erro de _cross-validation_ pode ser utilizado para tunar os hiperparâmetros do modelo.\n",
        "\n",
        "As escolhas mais comuns para $k$ são 5 e 10, ou seja, dividimos o conjunto de _cross-validation_ em 5 ou 10 partes iguais para a validação. Esses valores demonstraram de forma empírica levar às melhores estimativas do erro de teste real.\n",
        "\n",
        "Por fim, quando tivermos um modelo resolvido, avaliamos o seu desempenho com o conjunto de teste, intocado até este momento. Esse é o erro final do nosso modelo e é ele que devemos reportar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSvYImmLAK0O",
        "colab_type": "text"
      },
      "source": [
        "Um esquemático do $k$-_fold cross-validation_ é mostrado abaixo:\n",
        "\n",
        "![cross-validation](https://drive.google.com/uc?export=download&id=1WCSJJtXUsDIr1aUKJn1R_AV7JuLfLoB-)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfEdpeyzDkL7",
        "colab_type": "text"
      },
      "source": [
        "Muitas implementações do _cross-validation_ adicionam uma etapa a mais a todo processo: eles retreinam o modelo escolhido com todos os dados disponíveis. Uma vez que os hiperparâmetros do modelo já foram escolhidos por _cross-validation_, podemos nos dar ao luxo de utilizar todos os dados disponíveis para treinar o modelo e assim melhorar sua qualidade."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NHJFvaSGMmX",
        "colab_type": "text"
      },
      "source": [
        "Uma das desvantagens do $k$-_fold cross-validation_ é seu custo computacional. Quando maior o valor de $k$, mais iterações do método, e consequentemente, mais modelos deverão ser treinados. Por exemplo, com $k = 10$, teremos 10 iterações e 10 modelos inteiros sendo treinados. Dependendo do tipo e natureza do modelo, essa pode ser uma tarefa bastante demorada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO6MKmhWNAf1",
        "colab_type": "code",
        "outputId": "8736b963-dab3-476a-cc3b-3a0814ce518f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(digits, target, test_size=0.25)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1347, 64), (450, 64))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUvcPdh4OfiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = {\"criterion\": [\"gini\", \"entropy\"],\n",
        "              \"max_depth\": [2**i for i in range(5)],\n",
        "              \"min_samples_leaf\": [2**i for i in range(5)]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmjb7VF8NW7z",
        "colab_type": "code",
        "outputId": "2270eef5-2f53-4f9d-ea22-013cdf7769e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid=param_grid, cv=5)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "grid_search.cv_results_[\"mean_test_score\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
            "  DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1952487 , 0.1952487 , 0.1952487 , 0.1952487 , 0.1952487 ,\n",
              "       0.31106162, 0.31106162, 0.31106162, 0.31106162, 0.31106162,\n",
              "       0.62657758, 0.62435041, 0.62360802, 0.62286563, 0.62138085,\n",
              "       0.81811433, 0.81365999, 0.80697847, 0.79213066, 0.77208612,\n",
              "       0.83073497, 0.82182628, 0.81959911, 0.79584261, 0.77208612,\n",
              "       0.18856719, 0.18856719, 0.18856719, 0.18856719, 0.18856719,\n",
              "       0.33333333, 0.33333333, 0.33333333, 0.33333333, 0.33333333,\n",
              "       0.71640683, 0.71640683, 0.71566444, 0.71269488, 0.70749814,\n",
              "       0.8359317 , 0.84261321, 0.83073497, 0.80920564, 0.78544915,\n",
              "       0.84929473, 0.84484039, 0.83518931, 0.80920564, 0.78544915])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm2tj_qvQbZ7",
        "colab_type": "code",
        "outputId": "497c2a82-3c79-4fd5-b67f-bcd66bceef70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy', 'max_depth': 16, 'min_samples_leaf': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWt879J6Qq4v",
        "colab_type": "code",
        "outputId": "24bcce93-692e-4b31-8d67-dbbed52adc1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "best_tree_cv = grid_search.best_estimator_\n",
        "\n",
        "y_pred_test = best_tree_cv.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test, y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8955555555555555"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9r_RfSWNTv9",
        "colab_type": "code",
        "outputId": "73b8aa24-0628-481e-bf4d-74a853f703df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cv_scores = cross_val_score(tree, X_train, y_train, cv=5)\n",
        "\n",
        "cv_scores.mean(), cv_scores.std()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7854260434315775, 0.01376836671530103)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-5MpsTbFHzJ",
        "colab_type": "text"
      },
      "source": [
        "## _Leave-one-out cross-validation_\n",
        "\n",
        "Um caso especial do $k$-_fold cross-validation_ é o _leave-one-out_, que é obtido quando fazemos $k = n$, sendo $n$ o número de dados no conjunto de _cross-validation_. Em outras palavras, temos $n$ _folds_ e cada uma delas possui um único dado.\n",
        "\n",
        "A cada iteração do método, treinamos o modelo em $n-1$ dados e avaliamos sua performance de validação em um único dado. No final das $n$ iterações, temos $n$ erros $\\text{MSE}_{i}$ ($i \\in \\{1, 2, \\cdots, n\\}$). Novamente, o erro de validação final é obtido através da média desses $n$ erros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lepGaaLpKr8c",
        "colab_type": "text"
      },
      "source": [
        "O esquemático abaixo ilustra o método do _leave-one-out_:\n",
        "\n",
        "![cross-validation](https://drive.google.com/uc?export=download&id=1rhdwWmW3OWEP14Oyg7kIKBo8VnUhzUwv)\n",
        "\n",
        "Note como cada _fold_ agora é um único dado. Além disso, como há embaralhamento dos dados do conjunto original antes da separação inicial, o dado no _fold_ 1 não necessariamente é o primeiro dado do conjunto de dados original, nem o _fold_ 2 é o segundo dado original e assim por diante."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh_rIgwSLhy8",
        "colab_type": "text"
      },
      "source": [
        "Ao final das $n$ iterações do _leave-one-out_, podemos utilizar o erro de validação obtido para comparar o modelo com as alternativas. Ao fim de todo processo de _cross-validation_, idealmente teremos o melhor modelo com a melhor combinação de hiperparâmetros. Esse modelo deve ser então testado contra o conjunto de teste para obtenção da estimativa final do erro de teste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlOH-uvrMGdo",
        "colab_type": "text"
      },
      "source": [
        "A desvantagem do _leave-one-out_ é o agravante da desvantagem do _cross-validation_ em geral: agora temos que treinar $n$ modelos. Para grandes amostras de dados, isso pode ser definitivamente uma tarefa demorada.\n",
        "\n",
        "Em geral, vale mais a pena utilizar $k$-_fold cross-validation_ com $k = 5$ ou $k = 10$ do que _leave-one-out_, tanto do ponto de vista computacional, quanto do ponto de vista estatístico. Isso acontece, porque o erro de validação do _leave-one-out_ possui uma variância maior, devido às amostras de treinamento utilizadas serem muito semelhantes umas as outras, apesar do seu menor viés, devido ao seu maior número de iterações."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMdJQnFSd6Xw",
        "colab_type": "code",
        "outputId": "14e6329e-272d-4d47-96a5-c54942ffdf31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sample_idx = np.random.choice(len(digits), size=200, replace=False)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(digits[sample_idx], target[sample_idx], test_size=0.2)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((160, 64), (40, 64))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6f6Avtsecvy",
        "colab_type": "code",
        "outputId": "7b68ada2-45dd-49ac-fa71-8522a5f6cc38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "grid_search_loo = GridSearchCV(DecisionTreeClassifier(), param_grid=param_grid, cv=LeaveOneOut())\n",
        "\n",
        "grid_search_loo.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=LeaveOneOut(), error_score='raise-deprecating',\n",
              "             estimator=DecisionTreeClassifier(class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features=None,\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              presort=False, random_state=None,\n",
              "                                              splitter='best'),\n",
              "             iid='warn', n_jobs=None,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [1, 2, 4, 8, 16],\n",
              "                         'min_samples_leaf': [1, 2, 4, 8, 16]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4CmuCrBeoPY",
        "colab_type": "code",
        "outputId": "1a026fc6-e144-4287-f1f6-40d81ba27c45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "grid_search.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'entropy', 'max_depth': 16, 'min_samples_leaf': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l7YVYdFe9BM",
        "colab_type": "code",
        "outputId": "0f5eae74-b9fe-474a-de46-bccbf676fd07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "best_tree_loo = grid_search_loo.best_estimator_\n",
        "\n",
        "y_pred_test = best_tree_loo.predict(X_test)\n",
        "\n",
        "accuracy_score(y_test, y_pred_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.65"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OePA5QNY4yL",
        "colab_type": "text"
      },
      "source": [
        "## Procedimento geral\n",
        "\n",
        "Vamos revisitar a figura que abre este módulo:\n",
        "\n",
        "![scheme](https://scikit-learn.org/stable/_images/grid_search_workflow.png)\n",
        "\n",
        "Ele não é apenas uma boa _cover_ para o _notebook_, mas é também o esquemático de um bom processo de validação e teste, que resume tudo que mostramos com _cross-validation_ até agora.\n",
        "\n",
        "1. O _data set_ primeiro é separado em treinamento e teste (ou _hold-out_).\n",
        "2. Os dados de treinamento são utilizados para escolher os melhores parâmetros dos modelos através de _cross-validation_.\n",
        "3. Depois de obtermos o melhor modelo, ou seja, de encontrarmos a melhor combinação de parâmetros, retreinamos esse modelo com todos os dados de treinamento disponíveis.\n",
        "4. Por fim, utilizamos os dados de teste para fazer a avaliação final do modelo e reportar os resultados.\n",
        "\n",
        "Vale notar que, com _cross-validation_, não precisamos nos ater a encontrar parâmetros des modelos. Podemos utilizar _cross-validation_ para encontrar, por exemplo, as melhores formas de pré-processar nossos dados como normalização, padronização, adição de novas _features_ etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY54LavTkUaY",
        "colab_type": "text"
      },
      "source": [
        "## Referências\n",
        "\n",
        "* [Overfitting, bias-variance and learning curves](https://rmartinshort.jimdo.com/2019/02/17/overfitting-bias-variance-and-leaning-curves/)\n",
        "\n",
        "* [What is the difference between test set and validation set?](https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set)\n",
        "\n",
        "* [What is the Difference Between Test and Validation Datasets?](https://machinelearningmastery.com/difference-test-validation-datasets/)\n",
        "\n",
        "* [How to Implement Resampling Methods From Scratch In Python](https://machinelearningmastery.com/implement-resampling-methods-scratch-python/)\n",
        "\n",
        "* [Como criar K-Fold cross-validation na mão em Python](https://medium.com/data-hackers/como-criar-k-fold-cross-validation-na-m%C3%A3o-em-python-c0bb06074b6b)\n",
        "\n",
        "* [A Gentle Introduction to k-fold Cross-Validation](https://machinelearningmastery.com/k-fold-cross-validation/)\n",
        "\n",
        "* [Data Leakage in Machine Learning](https://machinelearningmastery.com/data-leakage-machine-learning/)\n",
        "\n",
        "* [Cross-validation: evaluating estimator performance](https://scikit-learn.org/stable/modules/cross_validation.html#leave-one-out-loo)\n",
        "\n",
        "* [Model evaluation: quantifying the quality of predictions](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)\n",
        "\n",
        "* [Tuning the hyper-parameters of an estimator](https://scikit-learn.org/stable/modules/grid_search.html)\n"
      ]
    }
  ]
}